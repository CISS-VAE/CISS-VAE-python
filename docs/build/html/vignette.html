

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to use CISS-VAE &mdash; CISS-VAE 1.0.18 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="_static/styles.css" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=14ed45bf"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="_static/copybutton.js?v=00122899"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Using create_missingness_prop_matrix: A Complete Guide" href="missingness_prop_vignette.html" />
    <link rel="prev" title="CISS-VAE Quickstart" href="quickstart.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            CISS-VAE
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">CISS-VAE Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html#quickstart">Quickstart</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">How to use CISS-VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="#running-the-ciss-vae-model">Running the CISS-VAE Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#avoiding-imputation-of-certain-entries">Avoiding imputation of certain entries</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#hyperparameter-tuning-with-optuna">Hyperparameter Tuning with Optuna</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#dataset-preparation">Dataset Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clustering-on-missingness-pattern">Clustering on missingness pattern</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#creating-a-clusterdataset-object">Creating a <code class="docutils literal notranslate"><span class="pre">ClusterDataset</span></code> object</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#create-a-searchspace-object">Create a SearchSpace object:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-the-autotune-function">Run the <code class="docutils literal notranslate"><span class="pre">autotune</span></code> function:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#optional-using-optuna-dashboard">(optional) Using Optuna Dashboard</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#saving-and-loading-models">Saving and loading models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#saving">Saving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-a-model">Loading a Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="missingness_prop_vignette.html">Using <code class="docutils literal notranslate"><span class="pre">create_missingness_prop_matrix</span></code>: A Complete Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="missingness_prop_vignette.html#integration-with-sample-clustering">Integration with sample clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="missingness_prop_vignette.html#integration-w-ciss-vae-pipeline">Integration w/ CISS-VAE pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="missingness_prop_vignette.html#full-workflow">Full workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="dni_vignette.html">Avoiding imputation undesired data entries</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">CISS-VAE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">How to use CISS-VAE</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/vignette.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-use-ciss-vae">
<h1>How to use CISS-VAE<a class="headerlink" href="#how-to-use-ciss-vae" title="Link to this heading"></a></h1>
</section>
<section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h1>
<p>The <strong>Clustering-Informed Shared-Structure Variational Autoencoder (CISS-VAE)</strong> is a flexible deep learning model for missing data imputation that accommodates all three types of missing data mechanisms: Missing Completely At Random (MCAR), Missing At Random (MAR), and Missing Not At Random (MNAR). While it is particularly well-suited to MNAR scenarios where missingness patterns carry informative signals, CISS-VAE also functions effectively under MAR assumptions.</p>
<p>A key feature of CISS-VAE is the use of unsupervised clustering to capture distinct patterns of missingness. Alongside cluster-specific representations, the method leverages shared encoder and decoder layers. This allows for knowledge transfer across clusters and enhances parameter stability, which is especially important when some clusters have small sample sizes. In situations where the data do not naturally partition into meaningful clusters, the model defaults to a pooled representation, preventing unnecessary complications from cluster-specific components.</p>
<p>Additionally, CISS-VAE incorporates an iterative learning procedure, with a validation-based convergence criterion recommended to avoid overfitting. This procedure significantly improves imputation accuracy compared to traditional Variational Autoencoder training approaches in the presence of missing values. Overall, CISS-VAE adapts across a range of missing data mechanisms, leveraging clustering only when it offers clear benefits, and delivering robust, accurate imputations under varying conditions of missingness.</p>
<p>There are two ways to run the CISS-VAE process. If you know what model
parameters you want to use, you can use the <a class="reference internal" href="_autosummary/ciss_vae.training.run_cissvae.run_cissvae.html#ciss_vae.training.run_cissvae.run_cissvae" title="ciss_vae.training.run_cissvae.run_cissvae"><code class="xref py py-func docutils literal notranslate"><span class="pre">ciss_vae.training.run_cissvae.run_cissvae()</span></code></a> function to
run the model once for the given set of parameters. If you want to tune
the model instead, you can use <a class="reference internal" href="_autosummary/ciss_vae.training.autotune.autotune.html#ciss_vae.training.autotune.autotune" title="ciss_vae.training.autotune.autotune"><code class="xref py py-func docutils literal notranslate"><span class="pre">ciss_vae.training.autotune.autotune()</span></code></a>.</p>
<p>The R package associated with this model can be found at [rCISS-VAE] (https://ciss-vae.github.io/rCISS-VAE/).</p>
</section>
<section id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Link to this heading"></a></h1>
<p>The CISS-VAE package is currently available for python, with an R
package to be released soon. It can be installed from either
<a class="reference external" href="https://github.com/CISS-VAE/CISS-VAE-python">github</a> or PyPI.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># From PyPI (not released yet)</span>
pip<span class="w"> </span>install<span class="w"> </span>ciss-vae
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># From GitHub (latest development version)</span>
pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/CISS-VAE/CISS-VAE-python.git
</pre></div>
</div>
<div>
<blockquote>
<div><p><strong>Note</strong></p>
<p>If you want run_cissvae to handle clustering, please install the
clustering dependencies scikit-learn, leidenalg, python-igraph with pip.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>scikit-learn<span class="w"> </span>leidenalg<span class="w"> </span>python-igraph

OR

pip<span class="w"> </span>install<span class="w"> </span>ciss-vae<span class="o">[</span>clustering<span class="o">]</span>
</pre></div>
</div>
</div></blockquote>
</div>
</section>
<section id="running-the-ciss-vae-model">
<h1>Running the CISS-VAE Model<a class="headerlink" href="#running-the-ciss-vae-model" title="Link to this heading"></a></h1>
<p>You can use your own dataset or load the example dataset included with this package.</p>
<p>To load the sample dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>from ciss_vae.data import load_example_dataset
df_missing, df_complete, clusters = load_example_dataset()
</pre></div>
</div>
</div>
</div>
<p>If you already know what parameters you want for your model (or do not want to use the <a class="reference internal" href="_autosummary/ciss_vae.training.autotune.autotune.html#ciss_vae.training.autotune.autotune" title="ciss_vae.training.autotune.autotune"><code class="xref py py-func docutils literal notranslate"><span class="pre">ciss_vae.training.autotune.autotune()</span></code></a> function), you can use the <a class="reference internal" href="_autosummary/ciss_vae.training.run_cissvae.run_cissvae.html#ciss_vae.training.run_cissvae.run_cissvae" title="ciss_vae.training.run_cissvae.run_cissvae"><code class="xref py py-func docutils literal notranslate"><span class="pre">ciss_vae.training.run_cissvae.run_cissvae()</span></code></a> function to perform the imputation.</p>
<p>The input dataset should be one of the following:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- A Pandas DataFrame  

- A NumPy array  

- A PyTorch tensor  
</pre></div>
</div>
<p>Missing values should be represented using np.nan or None.</p>
<p><strong>Assigning cluster labels</strong><br />
There are three options for assigning cluster labels to the data:<br />
1. Manually assign cluster labels and provide them to the function via the <code class="docutils literal notranslate"><span class="pre">clusters</span></code> argument.<br />
2. Let <code class="docutils literal notranslate"><span class="pre">run_cissvae()</span></code> determine clusters based on patterns of missingness in the data by setting <code class="docutils literal notranslate"><span class="pre">clusters</span> <span class="pre">=</span> <span class="pre">None</span></code>.<br />
- To use Kmeans clustering, set n_clusters to the desired number of clusters.<br />
- To use Leiden Clustering clustering, leave <code class="docutils literal notranslate"><span class="pre">n_clusters</span> <span class="pre">=</span> <span class="pre">None</span></code>.<br />
3. To cluster on proportion of missingness, leave <code class="docutils literal notranslate"><span class="pre">clusters</span> <span class="pre">=</span> <span class="pre">None</span></code> and provide a missingness proportion matrix with the <code class="docutils literal notranslate"><span class="pre">missingness_proportion_matrix</span></code> argument.<br />
- To use Kmeans clustering, set n_clusters to the desired number of clusters.<br />
- To use Leiden Clustering clustering, leave <code class="docutils literal notranslate"><span class="pre">n_clusters</span> <span class="pre">=</span> <span class="pre">None</span></code>.<br />
<details>
<summary>Click for more details on missingness proportion matrix</summary>
<p>For the missingness proportion matrix, (either a <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> or <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code>) the rows should correspond to samples, the columns correspond to features, and the values are proportion of missingness of each feature for each sample. For features with multiple timepoints (like biomarker data collected at multiple visits), you may choose to have one column per feature and let the value be the overall proportion of missingness for that feature across all timepoints. See the <a href="https://ciss-vae.readthedocs.io/en/latest/missingness_prop_vignette.html">clustering on missingness proportion tutorial</a> for more details.</p>
</details></p>
<p>To run the CISSVAE model with default parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>import pandas as pd
from ciss_vae.training.run_cissvae import run_cissvae
from ciss_vae.data import load_example_dataset

# optional, display vae architecture
from ciss_vae.utils.helpers import plot_vae_architecture

data, _, clusters = load_example_dataset()

imputed_data, vae = run_cissvae(data = data,
## Dataset params
    val_proportion = 0.1, ## Fraction of non-missing data held out for validation. Can input a list here if you want different proportions for different clusters. 
    replacement_value = 0.0, 
    columns_ignore = data.columns[:5], ## columns to ignore when selecting validation dataset (and clustering if you do not provide clusters). For example, demographic columns with no missingness.
    print_dataset = True, 

## Cluster params
    clusters = clusters, ## Where your cluster list goes. If none, will do clustering for you  
    n_clusters = None, ## If you want run_cissvae to do clustering and you know how many clusters your data should have, enter that number here
    # -- Params for Leiden Clustering --
    k_neighbors = 15,
    leiden_resolution = 0.5, ## Lower resolution = fewer clusters and bigger clusters, higher resolution = more, smaller clusters
    leiden_objective = &quot;CPM&quot;, 
    # -- End Params for Leiden Clustering --
    seed = 42,
    missingness_proportion_matrix = None,
    
## VAE model params
    hidden_dims = [150, 120, 60], ## Dimensions of hidden layers, in order. One number per layer. 
    latent_dim = 15, ## Dimensions of latent embedding
    layer_order_enc = [&quot;unshared&quot;, &quot;unshared&quot;, &quot;unshared&quot;], ## order of shared vs unshared layers for encode (can use u or s instead of unshared, shared)
    layer_order_dec=[&quot;shared&quot;, &quot;shared&quot;,  &quot;shared&quot;],  ## order of shared vs unshared layers for decode
    latent_shared=False, 
    output_shared=False, 
    batch_size = 4000, ## batch size for data loader
    return_model = True, ## if true, outputs imputed dataset and model, otherwise just outputs imputed dataset. Set to true to return model for `plot_vae_architecture`

## Initial Training params
    epochs = 1000, ## default 
    initial_lr = 0.01, ## default
    decay_factor = 0.999, ## default, factor learning rate is multiplied by after each epoch, prevents overfitting
    beta= 0.001, ## default
    device = None, ## If none, will use gpu if available, cpu if not. See torch.devices for info 

## Impute-refit loop params
    max_loops = 100, ## max number of refit loops
    patience = 2, ## number of loops to check after best_dataset updated. Can increase to avoid local extrema
    epochs_per_loop = None, ## If none, same as epochs
    initial_lr_refit = None, ## If none, picks up from end of initial training
    decay_factor_refit = None, ## If none, same as decay_factor
    beta_refit = None, ## if none, same as beta

## Other params
    verbose = False, 
    return_silhouettes = False, ## if true, will return silhouettes from clustering. If run_cissvae did not perform clustering, will return &quot;None&quot;
    return_history = False, ## if true, will return training MSE history as pandas dataframe
    return_clusters = False, ## if true, will return the cluster labels. Helpful if run_cissvae performs clustering
)

## OPTIONAL - PLOT VAE ARCHITECTURE
plot_vae_architecture(model = vae,
                        title = None, ## Set title of plot
                        ## Colors below are default
                        color_shared = &quot;skyblue&quot;, 
                        color_unshared =&quot;lightcoral&quot;,
                        color_latent = &quot;gold&quot;, # xx fix
                        color_input = &quot;lightgreen&quot;,
                        color_output = &quot;lightgreen&quot;,
                        figsize=(16, 8),
                        return_fig = False)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cluster dataset:
 ClusterDataset(n_samples=8000, n_features=30, n_clusters=4)
  • Original missing: 61800 / 200000 (30.90%)
  • Validation held-out: 13783 (9.97% of non-missing)
  • .data shape:     (8000, 30)
  • .masks shape:    (8000, 30)
  • .val_data shape: (8000, 30)
</pre></div>
</div>
<img alt="_images/6a2ee139389a7895bdaa37b24579ae01db6b630648e491a486cbe5f54181ffd8.png" src="_images/6a2ee139389a7895bdaa37b24579ae01db6b630648e491a486cbe5f54181ffd8.png" />
</div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">return_clusters</span></code> parameter to get the cluster labels.
Use the <code class="docutils literal notranslate"><span class="pre">return_history</span></code> parameter to get a dataframe with the training MSE history.</p>
<section id="avoiding-imputation-of-certain-entries">
<h2>Avoiding imputation of certain entries<a class="headerlink" href="#avoiding-imputation-of-certain-entries" title="Link to this heading"></a></h2>
<p>In some cases, not all missing entries in a dataset are viable for imputation. For example, biomarker values after time of death would not necessarily be reasonable to impute and therefore should be ignored during the impute-refit training loop. To set certain data entries as un-imputable, create a do_not_impute matrix of the same size as the dataset, with 0 for entries that are non-missing or viable for imputation and 1 for entries that are missing and non-viable for imputation.</p>
<p>This matrix (or pandas.Dataframe) can then be passed to the <code class="docutils literal notranslate"><span class="pre">run_cissvae()</span></code> function. Make sure that the do_not_impute matrix has the same column labels as the original data set to use the <code class="docutils literal notranslate"><span class="pre">cols_ignore</span></code> option to ignore certain columns during imputation.</p>
<p>For more information, see the <a class="reference external" href="https://ciss-vae.readthedocs.io/en/latest/dni_vignette.html">dni vignette</a></p>
</section>
</section>
<section id="hyperparameter-tuning-with-optuna">
<h1>Hyperparameter Tuning with Optuna<a class="headerlink" href="#hyperparameter-tuning-with-optuna" title="Link to this heading"></a></h1>
<p>The <a class="reference internal" href="_autosummary/ciss_vae.training.autotune.autotune.html#ciss_vae.training.autotune.autotune" title="ciss_vae.training.autotune.autotune"><code class="xref py py-func docutils literal notranslate"><span class="pre">ciss_vae.training.autotune.autotune()</span></code></a> function lets you tune the model’s hyperparameters with
optuna to get the best possible model.</p>
<section id="dataset-preparation">
<h2>Dataset Preparation<a class="headerlink" href="#dataset-preparation" title="Link to this heading"></a></h2>
<p>Your dataset should be one of the following:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- A Pandas DataFrame  

- A NumPy array  

- A PyTorch tensor  
</pre></div>
</div>
<p>Missing values should be represented using np.nan or None.</p>
<p>Once the dataset is loaded, the first step is to identify patterns of
missingness using clustering.</p>
</section>
<section id="clustering-on-missingness-pattern">
<h2>Clustering on missingness pattern<a class="headerlink" href="#clustering-on-missingness-pattern" title="Link to this heading"></a></h2>
<p>Before fitting the model, the dataset should clustered based on its
missingness pattern (i.e., which variables are missing in each
observation).</p>
<p>The built-in function can perfrom either leiden clustering or Kmeans clustering:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>from ciss_vae.utils.clustering import cluster_on_missing
data, _, clusters = load_example_dataset()
clusters, _ = cluster_on_missing(
    data, 
    cols_ignore=data.columns[:5], 
    n_clusters=None, 
    k_neighbors=500, ## use higher k for fewer clusters generally
    use_snn=True,
    leiden_resolution=0.005, ## higher resolution -&gt; more clusters
    leiden_objective=&quot;CPM&quot;,
    seed=42)
</pre></div>
</div>
</div>
</div>
<p>This function uses Leiden Clustering clustering to detect structure in binary
missingness masks, and will automatically determine the number of
clusters if not specified. If n_clusters is specified, uses KMeans.</p>
<p><strong>Options:</strong></p>
<ul class="simple">
<li><p>cols_ignore: list of columns to exclude when computing the missingness
pattern. Ex: identifiers</p></li>
<li><p>n_clusters: set this to use K-Means instead of nonparametric
clustering.</p></li>
</ul>
<p><strong>To cluster on proportion of missingness, see (tutorial)[https://ciss-vae.readthedocs.io/en/latest/missingness_prop_vignette.html] for more details.</strong></p>
</section>
</section>
<section id="creating-a-clusterdataset-object">
<h1>Creating a <code class="docutils literal notranslate"><span class="pre">ClusterDataset</span></code> object<a class="headerlink" href="#creating-a-clusterdataset-object" title="Link to this heading"></a></h1>
<p>After obtaining cluster labels, construct a <a class="reference internal" href="_autosummary/ciss_vae.classes.cluster_dataset.ClusterDataset.html#ciss_vae.classes.cluster_dataset.ClusterDataset" title="ciss_vae.classes.cluster_dataset.ClusterDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">ciss_vae.classes.cluster_dataset.ClusterDataset</span></code></a>. This is the object that is fed into the autotune function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>from ciss_vae.classes.cluster_dataset import ClusterDataset
from ciss_vae.training.autotune import SearchSpace, autotune

dataset = ClusterDataset(data = data,
cluster_labels = clusters,
val_proportion = 0.1, ## 10% non-missing data is default. You can also input a list if you want different val_proportions for each cluster
replacement_value = 0, ## value to replace all missing data with before running model. Could be set to 0 or random
columns_ignore = data.columns[:5] ## Tells ClusterDataset not to hold out entries demographic columns for validation
)
</pre></div>
</div>
</div>
</div>
<section id="create-a-searchspace-object">
<h2>Create a SearchSpace object:<a class="headerlink" href="#create-a-searchspace-object" title="Link to this heading"></a></h2>
<p>In the SearchSpace object, define the search space for each
hyperparameter. Each of the parameters in <a class="reference internal" href="_autosummary/ciss_vae.training.autotune.SearchSpace.html#ciss_vae.training.autotune.SearchSpace" title="ciss_vae.training.autotune.SearchSpace"><code class="xref py py-class docutils literal notranslate"><span class="pre">ciss_vae.training.autotune.SearchSpace</span></code></a> can be set as
either tunable or non-tunable.</p>
<p>Types of parameters:</p>
<ul class="simple">
<li><p>(min, max, step) -&gt; creates a range</p></li>
<li><p>[a, b, c] -&gt; select value from list</p></li>
<li><p>x -&gt; set param as non-tunable</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>## These are the default parameters. Please note these parameters may not be best for all datasets depending on size and complexity.

searchspace = SearchSpace(
                 num_hidden_layers=(1, 4), ## Set number of hidden layers
                 hidden_dims=[64, 512], ## Allowable dimensions of hidden layers
                 latent_dim=[10, 100],
                 latent_shared=[True, False],
                 output_shared=[True,False],
                 lr=(1e-4, 1e-3),
                 decay_factor=(0.9, 0.999),
                 beta=0.01,
                 num_epochs=1000,
                 batch_size=64,
                 num_shared_encode=[0, 1, 3],
                 num_shared_decode=[0, 1, 3],
                 encoder_shared_placement = [&quot;at_end&quot;, &quot;at_start&quot;, &quot;alternating&quot;, &quot;random&quot;], ## where should the shared layers be placed in the encoder
                 decoder_shared_placement = [&quot;at_end&quot;, &quot;at_start&quot;, &quot;alternating&quot;, &quot;random&quot;], ## where should the shared layers be placed in the decoder
                 refit_patience=2,
                 refit_loops=100,
                 epochs_per_loop = 1000,
                 reset_lr_refit = [True, False])
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-the-autotune-function">
<h2>Run the <code class="docutils literal notranslate"><span class="pre">autotune</span></code> function:<a class="headerlink" href="#run-the-autotune-function" title="Link to this heading"></a></h2>
<p>Once the search space is set, the autotune function can be run.</p>
<p>There are a few options for running the autotune function, depending on your goals.<br />
1. Default:<br />
- Tune on a random sample of parameters from the SearchSpace obbject. This is the traditional autotune behavior.<br />
- For this behavior, set <code class="docutils literal notranslate"><span class="pre">constant_layer_size=False</span></code> and <code class="docutils literal notranslate"><span class="pre">evaluate_all_orders=False</span></code>.<br />
2. Tune with constant layer size:<br />
- All layers will be the same size. The size will be one selected from searchspace.
(ex: if <code class="docutils literal notranslate"><span class="pre">searchspace.num_hidden_layers</span></code> = [64, 512], all layers will be 64 or all layers will be 512),<br />
- For this behavior, set <code class="docutils literal notranslate"><span class="pre">constant_layer_size=False</span></code><br />
3. Tune for all permutations of shared layer placement:<br />
- Will tune all possible layer orders/placements. Use <code class="docutils literal notranslate"><span class="pre">max_exhaustive_orders</span></code> to set a cap on the number of permutations to try.<br />
- For this behavior, set <code class="docutils literal notranslate"><span class="pre">evaluate_all_orders=True</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>best_imputed_df,  best_model, study, results_df = autotune(
    search_space = searchspace,
    train_dataset = dataset,                   # ClusterDataset object
    save_model_path=None,
    save_search_space_path=None,
    n_trials=20,
    study_name=&quot;vae_autotune&quot;,                 # Default study name
    device_preference=&quot;cuda&quot;,
    show_progress=False,                       # Show progress bar for training
    optuna_dashboard_db=None,                  # If using optuna dashboard set db location here
    load_if_exists=True,                       # If using optuna dashboard, if study by &#39;study_name&#39; already exists, will load that study
    seed = 42,                                 # Sets seed for random order of shared/unshared layers
)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[I 2025-10-09 15:52:05,032] A new study created in memory with name: vae_autotune
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Warning] CUDA requested but not available. Falling back to CPU.
Starting Optuna optimization with 20 trials...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/nfs/vaithid1/CISS-VAE/CISS-VAE/src/ciss_vae/training/autotune.py:549: ExperimentalWarning: set_metric_names is experimental (supported from v3.2.0). The interface can change in the future.
  study.set_metric_names([&quot;Validation MSE&quot;])
[I 2025-10-09 16:12:32,538] Trial 0 finished with value: {&#39;Validation MSE&#39;: 5.61246919631958} and parameters: {&#39;num_hidden_layers&#39;: 1, &#39;hidden_dim_0&#39;: 512, &#39;latent_dim&#39;: 10, &#39;latent_shared&#39;: True, &#39;output_shared&#39;: True, &#39;lr&#39;: 0.00039843586858746887, &#39;decay_factor&#39;: 0.9684395881174177, &#39;num_shared_encode&#39;: 3, &#39;num_shared_decode&#39;: 0, &#39;encoder_shared_placement&#39;: &#39;at_start&#39;, &#39;decoder_shared_placement&#39;: &#39;at_end&#39;, &#39;reset_lr_refit&#39;: False}. Best is trial 0 with value: 5.61246919631958.
</pre></div>
</div>
</div>
</div>
</section>
<section id="optional-using-optuna-dashboard">
<h2>(optional) Using Optuna Dashboard<a class="headerlink" href="#optional-using-optuna-dashboard" title="Link to this heading"></a></h2>
<p>You can use <a class="reference external" href="https://optuna-dashboard.readthedocs.io/en/stable/getting-started.html">optuna
dashboard</a>
to visualize the importance of your tuning parameters. If you use VSCode
or <a class="reference external" href="https://positron.posit.co/download.html">Positron</a> there is an
extension for viewing optuna dashboards in your development environment.</p>
<p><img alt="Screenshot of Optuna Dashboard" src="_images/optuna_dash_v1.png" /></p>
<p>The optuna database file can be opened via commandline as well. (tutorial)[https://optuna-dashboard.readthedocs.io/en/stable/getting-started.html#command-line-interface]</p>
<p>To use optuna dashboard, set your database url in the autotune function. You
can have multiple autotune ‘studies’ in the same database.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>best_imputed_df,  best_model, study, results_df = autotune(
    search_space = searchspace,
    train_dataset = dataset,                   # &#39;ClusterDataset&#39; object
    save_model_path=None,
    save_search_space_path=None,
    n_trials=20,
    study_name=&quot;vae_autotune&quot;,                 # Default study name
    device_preference=&quot;cuda&quot;,
    show_progress=False,                       # Show progress bar for training
    optuna_dashboard_db=&quot;sqlite:///db.sqlite3&quot;,                  # If using optuna dashboard set db location here, otherwise set to None
    load_if_exists=True,                       # Continues previous study by study_name if one exists. If false, will give error if study_name already exists in the set dashboard
    seed = 42,
)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="saving-and-loading-models">
<h1>Saving and loading models<a class="headerlink" href="#saving-and-loading-models" title="Link to this heading"></a></h1>
<section id="saving">
<h2>Saving<a class="headerlink" href="#saving" title="Link to this heading"></a></h2>
<p>If you want to save your model and load it later, there are two options.</p>
<p>To save the model weights after training:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## assuming your trained model is called &#39;model&#39;</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;trained_vae.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you want to save the entire model:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;trained_vae_full.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="loading-a-model">
<h2>Loading a Model<a class="headerlink" href="#loading-a-model" title="Link to this heading"></a></h2>
<p>To reload the model for imputation or further training:</p>
<ol class="arabic simple">
<li><p>Re-create the model architecture with the same settings used during training</p></li>
<li><p>Load the saved weights</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ciss_vae.classes.vae</span><span class="w"> </span><span class="kn">import</span> <span class="n">CISSVAE</span>

<span class="c1"># 1. Define the architecture (must match the saved model!)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CISSVAE</span><span class="p">(</span>
    <span class="n">input_dim</span><span class="o">=...</span><span class="p">,</span>
    <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="o">...</span><span class="p">],</span>
    <span class="n">layer_order_enc</span><span class="o">=</span><span class="p">[</span><span class="o">...</span><span class="p">],</span>
    <span class="n">layer_order_dec</span><span class="o">=</span><span class="p">[</span><span class="o">...</span><span class="p">],</span>
    <span class="n">latent_shared</span><span class="o">=...</span><span class="p">,</span>
    <span class="n">num_clusters</span><span class="o">=...</span><span class="p">,</span>
    <span class="n">latent_dim</span><span class="o">=...</span><span class="p">,</span>
    <span class="n">output_shared</span><span class="o">=...</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;trained_vae.pt&quot;</span><span class="p">))</span>



<span class="c1">## optional to get imputed dataset. </span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ciss_vae.utils.helpers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_imputed_df</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1">## assuming dataset is a ClusterDataset</span>
<span class="n">data_loader</span> <span class="o">=</span>  <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">)</span>

<span class="n">imputed_df</span> <span class="o">=</span> <span class="n">get_imputed_df</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quickstart.html" class="btn btn-neutral float-left" title="CISS-VAE Quickstart" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="missingness_prop_vignette.html" class="btn btn-neutral float-right" title="Using create_missingness_prop_matrix: A Complete Guide" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Yasin Khadem Charvadeh, Danielle Vaithilingam, Kenneth Seier, Katherine S. Panageas, Mithat Gönen, Yuan Chen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>